# U-SAM é¡¹ç›®æ¦‚è§ˆä¸å¤ç°æŒ‡å— âœ…

## 1) é¡¹ç›®åšä»€ä¹ˆ ğŸ’¡
- åç§°ï¼šU-SAM â€” "Tuning Vision Foundation Models for Rectal Cancer Segmentation from CT Scans"ã€‚
- ä»»åŠ¡ï¼šåŸºäº SAMï¼ˆSegment Anything Modelï¼‰ä¸è‡ªå®šä¹‰ä¸‹é‡‡æ · UNet backbone çš„ç»„åˆï¼Œé’ˆå¯¹ç›´è‚ ç™Œ CT åˆ‡ç‰‡åšåŒ»å­¦å›¾åƒåˆ†å‰²ï¼ˆCARE æ•°æ®é›†ä¸ºä¸»ï¼Œå¦æ”¯æŒ WORD æ•°æ®é›†ï¼‰ã€‚
- è¾“å‡ºï¼šè®­ç»ƒå¾—åˆ°çš„åˆ†å‰²æ¨¡å‹æ£€æŸ¥ç‚¹ï¼ˆ.pthï¼‰ä»¥åŠ `mean_dice`ã€`miou` ç­‰è¯„ä¼°æŒ‡æ ‡ã€‚

---

## 2) é¡¹ç›®ç»“æ„ï¼ˆå…³é”®æ–‡ä»¶/ç›®å½•ï¼‰ ğŸ”§
- `u-sam.py`ï¼šä¸»è®­ç»ƒ/è¯„ä¼°è„šæœ¬ï¼ˆå‘½ä»¤è¡Œå‚æ•°ã€æ•°æ®åŠ è½½ã€æ¨¡å‹ã€è®­ç»ƒ/è¯„ä¼°å¾ªç¯ã€ä¿å­˜ checkpointï¼‰ã€‚
- `backbone.py`ï¼šè‡ªå®šä¹‰ä¸‹é‡‡æ · UNetï¼ˆæå–å›¾åƒç‰¹å¾å¹¶è¾“å‡ºç»™ SAM æ¨¡å—ï¼‰ã€‚
- `dataset/rectum_dataloader.py`ï¼šCAREï¼ˆrectumï¼‰æ•°æ® loaderï¼Œè¯»å– `.npz`ã€CSVã€ç”Ÿæˆ promptï¼ˆboxes/pointsï¼‰å¹¶åšå¢å¼ºã€‚
- `dataset/word_dataloader.py`ï¼šWORD æ•°æ® loaderã€‚
- `util/`ï¼šè¾…åŠ©å‡½æ•°ï¼ˆåˆ†å¸ƒå¼ã€collateã€metric è®¡ç®—ã€ä¿å­˜ç­‰ï¼‰ã€‚
- `weight/`ï¼šç”¨äºæ”¾ç½®é¢„è®­ç»ƒ SAM æƒé‡ï¼ˆå¦‚ `sam_vit_b_01ec64.pth`ï¼‰ã€‚
- `train_sam.sh`ï¼šç¤ºä¾‹å¤šå¡åˆ†å¸ƒå¼è®­ç»ƒå‘½ä»¤ã€‚
- `Annotation_Example/`ï¼šè‹¥å¹²ç¤ºä¾‹ `.npz` æ–‡ä»¶ä¸å¯è§†åŒ–ç¤ºä¾‹ï¼Œå¯å‚è€ƒæ•°æ®æ ¼å¼ã€‚
- `test_paths.py`ï¼šç”¨äºæ£€æŸ¥æ•°æ®ç›®å½•ç»“æ„ä¸æ–‡ä»¶æ˜¯å¦å°±ä½çš„å°è„šæœ¬ã€‚

---

## 3) æ•°æ®ä¸æ ¼å¼è¦æ±‚ï¼ˆDataV6 / CAREï¼‰ ğŸ“
- ä»£ç é»˜è®¤æœŸæœ›å­˜åœ¨åä¸º `DataV6` çš„æ•°æ®æ ¹ç›®å½•ï¼ˆé»˜è®¤ä½ç½®ï¼šé¡¹ç›®çˆ¶ç›®å½•ä¸‹ `DataV6`ï¼Œå³ `../DataV6`ï¼‰ã€‚

å»ºè®®çš„æ•°æ®ç»„ç»‡ï¼š
```
DataV6/
  â”œâ”€ train/
  â”‚   â”œâ”€ train_bbox.csv       # CSV: æ¯è¡Œ [basename, bbox]
  â”‚   â””â”€ train_npz/           # å¤šä¸ª .npzï¼Œæ¯ä¸ªå«é”®: 'image', 'label'
  â””â”€ test/
      â”œâ”€ test_bbox.csv
      â””â”€ test_npz/
```
- `.npz` æ–‡ä»¶ï¼ˆsee `Annotation_Example/`ï¼‰ï¼šåŒ…å« `image`ï¼ˆç°åº¦/å½’ä¸€åŒ–å›¾åƒï¼Œè„šæœ¬ä¸­ä¼šä¹˜ 255 å†åš CLAHEï¼‰ï¼Œå’Œ `label`ï¼ˆæ ‡æ³¨æ©ç ï¼Œæ•´æ•°ç±»æ ‡ç­¾ï¼‰ã€‚
- CSVï¼šç¬¬ 1 åˆ—ä¸ºæ–‡ä»¶åï¼ˆä¸å« .npz åç¼€ï¼‰ï¼Œç¬¬ 2 åˆ—ä¸º bboxï¼ˆå­—ç¬¦ä¸²å½¢å¼çš„ listï¼Œä¾‹å¦‚ `[x1, y1, x2, y2]`ï¼‰ã€‚
- å¯¹äº `word` æ•°æ®é›†ï¼Œ`u-sam.py` ä¸­çš„ `args.root` ä¸ºç¡¬ç¼–ç è·¯å¾„ï¼Œéœ€è¦æŒ‰æœ¬åœ°ä½ç½®ä¿®æ”¹æˆ–æ›¿æ¢ä¸º `DataV6` ç»“æ„ã€‚

---

## 4) ç¯å¢ƒä¸ä¾èµ–ï¼ˆå»ºè®®ï¼‰ ğŸ§©
- Python: æ¨è 3.9.xï¼ˆREADME ä¸­å»ºè®® `python==3.9.12`ï¼‰ã€‚
- PyTorch: `torch==1.11.0`ï¼Œ`torchvision==0.12.0`ï¼ˆåŒ¹é… READMEï¼‰ã€‚
- å…¶ä»–ï¼š`numpy==1.21.5`ã€`matplotlib==3.5.2`ã€`albumentations`ã€`scipy`ã€`pandas` ç­‰ã€‚
- å¿…é¡»ï¼šåœ¨ `weight/` ä¸‹æ”¾ç½® SAM çš„é¢„è®­ç»ƒæƒé‡ï¼ˆé»˜è®¤ä½¿ç”¨ ViT-Bï¼‰
  - e.g. `weight/sam_vit_b_01ec64.pth`
  - å¯ä» Segment Anything å®˜æ–¹é“¾æ¥ä¸‹è½½ï¼ˆREADME ä¸­æœ‰ç›´é“¾ï¼‰ã€‚

---

## 5) å¦‚ä½•å¤ç°ï¼ˆæœ€å°æ­¥éª¤ï¼‰ â–¶ï¸
1. å…‹éš†æˆ–æ‹·è´ä»£ç åˆ°æœ¬åœ°å¹¶è¿›å…¥é¡¹ç›®ç›®å½•ï¼ˆç¡®ä¿ `u-sam.py` åœ¨è¯¥ç›®å½•ï¼‰ã€‚
2. å‡†å¤‡æ•°æ®ï¼ˆCAREï¼‰ï¼šæŒ‰ä¸Šé¢çš„ DataV6 ç»“æ„ç»„ç»‡æ•°æ®ï¼›ä¹Ÿå¯å‚è€ƒ `Annotation_Example/` çš„ç¤ºä¾‹æ–‡ä»¶æ ¼å¼ã€‚
3. ä¸‹è½½ SAM é¢„è®­ç»ƒæƒé‡æ”¾åˆ° `weight/`ï¼š
   - å¸¸ç”¨ï¼š`sam_vit_b_01ec64.pth`
4. å®‰è£…ä¾èµ–ï¼ˆç¤ºä¾‹ï¼‰:
   - pip install torch==1.11.0 torchvision==0.12.0 numpy==1.21.5 matplotlib albumentations scipy pandas
5. æ£€æŸ¥æ•°æ®è·¯å¾„ï¼ˆå¯è¿è¡Œï¼‰ï¼š
   - `python test_paths.py` ï¼ˆè„šæœ¬ä¼šæ£€æµ‹ DataV6 çš„ train/testã€CSV ä¸ .npz æ–‡ä»¶ï¼‰
6. å•å¡è®­ç»ƒï¼ˆCAREï¼‰ï¼š
   - `python u-sam.py --epochs 100 --batch_size 24 --dataset rectum`
7. å¤šå¡è®­ç»ƒï¼ˆç¤ºä¾‹ï¼Œ8 å¡ DDPï¼‰ï¼š
   - `bash train_sam.sh` æˆ–å‚ç…§ `train_sam.sh` ä¸­çš„å‘½ä»¤ä¿®æ”¹ `CUDA_VISIBLE_DEVICES` ç­‰ã€‚
8. è¯„ä¼°ï¼š
   - `python u-sam.py --dataset rectum --eval --resume /path/to/checkpoint.pth`
   - è¾“å‡ºåœ¨æ§åˆ¶å°åŠ `exp/U-SAM-Rectum/prompt=<...>/log.txt` ä¸­è®°å½•æ—¥å¿—å’Œæœ€ä½³ checkpointï¼ˆä¾‹å¦‚ `best_<mean_dice>_<miou>.pth`ï¼‰ã€‚

---

## 6) æ¨¡å‹ä¸è®­ç»ƒç»†èŠ‚ï¼ˆå¦‚ä½•åšçš„ï¼‰ âš™ï¸
- Model: `SAM` wrapperï¼ˆåœ¨ `u-sam.py` ä¸­ï¼‰ç»“åˆä¸‹é‡‡æ · `UNet`ï¼ˆ`backbone.py`ï¼‰ä¸ SAM çš„ image encoder + mask decoderã€‚è®­ç»ƒæ—¶ï¼š
  - å¦‚æœé€‰æ‹© promptï¼ˆboxes/pointsï¼‰ï¼ŒSAM çš„ prompt_encoder ä¼šåˆ©ç”¨å®ƒä»¬æ¥ç”Ÿæˆ sparse/dense embeddingsã€‚
  - backbone è¾“å‡ºä½åˆ†è¾¨ç‡ç‰¹å¾ä¾› SAM image_encoder ä½¿ç”¨ã€‚
- Loss: æ··åˆäº¤å‰ç†µï¼ˆCEï¼‰ä¸ Dice lossï¼ˆä»¥ 0.6 çš„æƒé‡å¹³è¡¡ï¼Œè¯¦è§ `calc_loss`ï¼‰ã€‚
- Metric: class-wise Dice å’Œ IoUï¼Œåœ¨ `evaluate()` ä¸­æ±‡æ€»å¹¶è¿”å› `mean_dice` ä¸ `miou`ã€‚
- Prompt æ¨¡å¼ï¼ˆCLI å‚æ•° `--prompt_mode`ï¼‰: 0=æ— æç¤º, 1=GT boxes, 2=GT points, 3=boxes+pointsï¼ˆå½±å“è®­ç»ƒä¸ eval æ—¶ä½¿ç”¨çš„ promptsï¼‰ã€‚
- å›¾åƒå½’ä¸€åŒ–ï¼šåœ¨ `main()` ä¸­ç¡¬ç¼–ç äº† `pixel_mean` ä¸ `pixel_std`ï¼Œå¹¶åœ¨ `SAM.forward` ä¸­è¿›è¡Œæ ‡å‡†åŒ–ï¼ˆæ‰€ä»¥ä¸è¦å†åœ¨å¤–éƒ¨é‡å¤ normalizeï¼‰ã€‚

---

## 7) å¸¸è§æ³¨æ„äº‹é¡¹ & æ’é”™ ğŸ”
- ç¡®ä¿ `weight/` ä¸‹æœ‰å¯¹åº”çš„ SAM é¢„è®­ç»ƒæƒé‡ï¼Œé»˜è®¤æ˜¯ `vit_b`ã€‚
- æ•°æ®æ ¼å¼é”™è¯¯ï¼ˆCSV æˆ– .npz é”™è¯¯ï¼‰ä¼šå¯¼è‡´ dataloader æŠ¥é”™ï¼›å…ˆç”¨ `test_paths.py` éªŒè¯ã€‚
- è‹¥ä½¿ç”¨ `--dataset word`ï¼Œéœ€ä¿®æ”¹æˆ–ä¼ å…¥åˆé€‚çš„ `args.root`ï¼Œå¦åˆ™é»˜è®¤è·¯å¾„ä¸ºç©ºæˆ–ä¸ºç¡¬ç¼–ç è·¯å¾„ã€‚
- å½“è®­ç»ƒå‡ºç°æ˜¾å­˜ä¸è¶³ï¼Œå¯å°è¯•å‡å° `--batch_size` æˆ–ç”¨æ¢¯åº¦ç´¯ç§¯/æ›´å°å›¾åƒå°ºå¯¸ï¼ˆ`--img_size`ï¼‰ã€‚
- è®­ç»ƒè¿‡ç¨‹ä¸­è¾“å‡ºæ—¥å¿—ä¼šå†™å…¥ `exp/U-SAM-Rectum/prompt=<...>/log.txt`ï¼Œè®­ç»ƒæ£€æŸ¥ç‚¹åŒç›®å½•ä¿å­˜ã€‚

---

## 8) å°è´´å£« âœ…
- æŸ¥çœ‹ `Annotation_Example/` æ¥äº†è§£ `.npz` æ–‡ä»¶å’Œæ ‡ç­¾ç»„ç»‡ã€‚
- è‹¥è¦å¤ç°å®éªŒè®ºæ–‡ä¸­çš„å…·ä½“è¶…å‚ï¼ˆå¦‚è®­ç»ƒè½®æ•°ã€batch sizeï¼‰ï¼Œå‚è§ `README.md` ä¸­æ¨èè®¾ç½®ã€‚
- æƒ³è°ƒè¯•å°æ ·æœ¬æˆ–å¯è§†åŒ–å•å¼ ç»“æœï¼šåœ¨ `u-sam.py` ä¸­å¼€å¯ `--eval` å¹¶ä¼ å…¥ `--resume`ï¼Œ`evaluate(..., visual=True)` ä¼šæ‰“å°å¹¶å¯è§†åŒ–æ ·ä¾‹ï¼ˆä»£ç ä¸­å·²æœ‰ `visualize()` è°ƒç”¨ç‚¹ï¼Œéœ€ç¡®ä¿å¯è§†åŒ–å‡½æ•°å­˜åœ¨/å¯ç”¨ï¼‰ã€‚

---

å¦‚æœä½ å¸Œæœ›ï¼Œæˆ‘å¯ä»¥ï¼š
1) æ ¹æ®ä½ æœ¬åœ°çš„æ•°æ®ä½ç½®ï¼Œç”Ÿæˆä¸€ä¸ª `DataV6` ç›®å½•ç»“æ„æ£€æŸ¥è„šæœ¬ï¼ˆæˆ–æ›´æ–° `test_paths.py`ï¼‰ï¼Œæˆ–è€…
2) å¸®ä½ ä¸€æ­¥æ­¥æ‰§è¡Œä»åˆ›å»ºè™šæ‹Ÿç¯å¢ƒã€å®‰è£…ä¾èµ–åˆ°è¿è¡Œä¸€æ¬¡å°è§„æ¨¡è®­ç»ƒ/è¯„ä¼°çš„å…·ä½“å‘½ä»¤ã€‚ğŸ”§

---

## 9) ä½¿ç”¨è®­ç»ƒå¥½çš„ `.pth` å¤„ç† `.npz` æ–‡ä»¶ï¼ˆæ¨ç†ï¼‰ ğŸ”

ä¸‹é¢ç»™å‡ºä¸¤ç§å¸¸è§åšæ³•ï¼šæ‰¹é‡è¯„ä¼°ï¼ˆè€è„šæœ¬ï¼‰ä¸å•å¼ /è‡ªå®šä¹‰ `.npz` æ¨ç†å¹¶ä¿å­˜é¢„æµ‹ï¼ˆæ¨èï¼‰ã€‚

### æ–¹æ³• A â€” ä½¿ç”¨ `u-sam.py` çš„ `--eval`ï¼ˆé€‚åˆå·²æŒ‰ DataV6 ç»„ç»‡çš„æµ‹è¯•é›†ï¼‰
- å‡†å¤‡ `DataV6/test/test_npz` ä¸ `test_bbox.csv`ï¼ˆç¡®ä¿æ–‡ä»¶ååœ¨ CSV ä¸­èƒ½æ‰¾åˆ°ï¼‰ã€‚
- è¿è¡Œå‘½ä»¤ï¼š

```bash
python u-sam.py --dataset rectum --eval --resume /path/to/best_<mean_dice>_<miou>.pth
```

- è¾“å‡ºï¼šæ§åˆ¶å°æ˜¾ç¤ºè¯„ä¼°æŒ‡æ ‡ï¼ˆmean_dice, miouï¼‰ï¼›è„šæœ¬é»˜è®¤ä¸å°†å•å¼ é¢„æµ‹ä¿å­˜åˆ°ç£ç›˜ï¼Œå¦‚éœ€ä¿å­˜å‚è§æ–¹æ³• Bã€‚

### æ–¹æ³• B â€” æ¨èï¼šå•å¼  `.npz` æ¨ç†å¹¶ä¿å­˜ç»“æœï¼ˆç¤ºä¾‹è„šæœ¬ï¼‰
- ä½¿ç”¨åœºæ™¯ï¼šè°ƒè¯•ã€å¯è§†åŒ–æˆ–å¯¹ä»»æ„ `.npz` é€ä¸ªæ¨ç†å¹¶æŠŠé¢„æµ‹ mask ä¿å­˜ä¸º `.npz`/`.png`ã€‚
- æ–°å»º `inference_npz.py`ï¼ˆæ”¾åœ¨é¡¹ç›®æ ¹ç›®å½•ï¼‰ï¼Œä»¥ä¸‹ä¸ºæœ€å°ç¤ºä¾‹ï¼š

```python
import argparse
import numpy as np
import torch
from util.misc import nested_tensor_from_tensor_list
from u-sam import parse_args, SAM

# ç®€åŒ–ç¤ºä¾‹ï¼Œä¸å«å…¨éƒ¨å¼‚å¸¸å¤„ç†

def load_npz_and_preprocess(path, img_size):
    npz = np.load(path)
    img = npz['image']  # assumed grayscale normalized [0,1]
    # apply same CLAHE preprocessing as dataloader if desired (or reuse albumentations)
    # resize to img_size
    from scipy.ndimage import zoom
    h, w = img.shape
    if (w, h) != (img_size, img_size):
        img = zoom(img, (img_size / w, img_size / h), order=3)
    img = np.uint8(img * 255)
    # convert to 3-channel float tensor
    img = img.astype(float) / 255
    img = torch.tensor(img).unsqueeze(0).repeat(3, 1, 1).float()
    return img


def main():
    parser = argparse.ArgumentParser()
    parser.add_argument('--npz', required=True)
    parser.add_argument('--resume', required=True)
    parser.add_argument('--img_size', type=int, default=224)
    parser.add_argument('--device', default='cuda')
    args = parser.parse_args()

    device = torch.device(args.device)

    # build args for model like in u-sam
    am = argparse.Namespace()
    am.img_size = args.img_size
    am.sam_num_classes = 3
    am.use_gt_box = False
    am.use_gt_pts = False
    am.use_psd_box = False
    am.use_psd_pts = False
    am.use_psd_mask = False
    am.sam_weight = 'weight/sam_vit_b_01ec64.pth'

    model = SAM(am)
    ckpt = torch.load(args.resume, map_location='cpu')
    model.load_state_dict(ckpt['model'])
    model.to(device)
    model.eval()

    img = load_npz_and_preprocess(args.npz, args.img_size)
    samples = nested_tensor_from_tensor_list([img])  # wraps tensor as NestedTensor

    # provide a dummy target (model's eval branch expects targets list)
    dummy_mask = torch.zeros((args.img_size, args.img_size), dtype=torch.long)
    target = {'mask': dummy_mask, 'id': torch.tensor(0)}

    with torch.no_grad():
        outputs = model(samples.to(device), [target])
    # model in eval mode returns (masks, dice_a, dice_b, iou_a, iou_b)
    pred_masks = outputs[0]
    pred = pred_masks[0].cpu().numpy().astype(np.uint8)

    # save prediction
    out_path = args.npz.replace('.npz', '_pred.npz')
    np.savez_compressed(out_path, mask=pred)
    print('Saved prediction to', out_path)

if __name__ == '__main__':
    main()
```

- ä½¿ç”¨ç¤ºä¾‹ï¼š

```bash
python inference_npz.py --npz DataV6/test/test_npz/0001.npz --resume exp/U-SAM-Rectum/prompt=no_prompt/best_0.656473_0.491037.pth --img_size 224 --device cuda
```

- å¯é€‰ï¼šæŠŠä¿å­˜çš„ `.npz` æ–‡ä»¶ä¸­çš„ `mask` ç”¨ `matplotlib` æˆ–å…¶ä»–å·¥å…·ä¿å­˜ä¸º `.png` ä»¥ä¾¿æŸ¥çœ‹ã€‚

### å°æç¤º
- è‹¥ä½ å¸Œæœ›æ‰¹é‡å¯¹ä¸€ä¸ªæ–‡ä»¶å¤¹è¿è¡Œè¯¥è„šæœ¬ï¼Œå¯æŠŠä¸Šé¢çš„æ­¥éª¤æ”¾å…¥å¾ªç¯å¹¶æŠŠç»“æœå­˜åˆ°æŒ‡å®šè¾“å‡ºç›®å½•ã€‚
- å¦‚éœ€é«˜è´¨é‡å¯è§†åŒ–æˆ–åå¤„ç†ï¼ˆè¿é€šåŸŸã€å¹³æ»‘ç­‰ï¼‰ï¼Œå»ºè®®åœ¨ä¿å­˜åå†è¡Œå¤„ç†ã€‚

---

ä½œè€…ï¼šè‡ªåŠ¨ç”Ÿæˆæ€»ç»“ï¼ˆåŸºäºä»“åº“ä¸­çš„ `README` ä¸æºç è§£æï¼‰
